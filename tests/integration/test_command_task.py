from dataclasses import dataclass
import json
from pathlib import Path, PurePath
from typing import List

import pytest
from click.testing import CliRunner
from conftest import tmp_dir_path

from utils import validate_json
from tidecli.main import task


# TASK LIST


@pytest.mark.parametrize(
    "exercise_path, expected_task_ids",
    [
        ("users/test-user-1/course-1/exercise-1", ["t1", "t2", "t3"]),
        ("users/test-user-1/course-1/exercise-2", ["33232123"]),
        ("users/test-user-1/course-2/exercise-a", ["t1", "t2", "t4"]),
        ("users/test-user-1/course-2/exercise-b", ["t1"]),
    ],
)
def test_task_list_outputs_expected_data(
    exercise_path: str, expected_task_ids: List[str]
):
    runner = CliRunner()
    result = runner.invoke(
        task,
        ["list", exercise_path],
    )

    assert all([task_id in result.output for task_id in expected_task_ids])


def test_task_list_with_json_flag_outputs_valid_json():
    runner = CliRunner()
    result = runner.invoke(
        task,
        ["list", "users/test-user-1/course-1/exercise-1", "--json"],
    )

    validate_json(result.output)


def test_task_list_with_json_flag_outputs_expected_data():
    # TODO: the current "task list --json" prints tons of unnecessary information
    pass


# TASK CREATE


@dataclass
class ExpectedTaskFile:
    filename: str
    content: str | None = None  # None is used to ignore the content during tests


@pytest.mark.parametrize(
    "course_path, exercise_id, task_id, expected_files",
    [
        # task with no supplementary files
        (
            "users/test-user-1/course-2",
            "exercise-a",
            "t2",
            [
                ExpectedTaskFile(
                    filename="hello.py",
                    content='print("marsu maiskuttaa")',
                ),
                ExpectedTaskFile(filename=".timdata"),
            ],
        ),
        # task with supplementary files defined in markdown
        (
            "users/test-user-1/course-1",
            "exercise-1",
            "t2",
            [
                ExpectedTaskFile(
                    filename="animals.py"
                    # TODO: how to handle file content with BYCODE tags
                ),
                ExpectedTaskFile(
                    filename="kissa.txt",
                    content="istuu\nja\nnaukuu\n",
                ),
                ExpectedTaskFile(filename="koira.dat", content="seisoo ja haukkuu"),
                ExpectedTaskFile(filename=".timdata"),
            ],
        ),
        # task with supplementary files autogenerated by TIM
        (
            "users/test-user-1/course-1",
            "exercise-1",
            "t3",
            [
                ExpectedTaskFile(
                    filename="hello.cs"
                ),
                ExpectedTaskFile(filename="t3.csproj"),
                ExpectedTaskFile(filename=".timdata"),

                ]
            )
        # TODO: task with supplementary files from TIM source
        # TODO: task with supplementary files from external source
    ],
)
def test_create_single_task_creates_files_with_expected_content(
    tmp_dir,
    course_path: str,
    exercise_id: str,
    task_id: str,
    expected_files: List[ExpectedTaskFile],
):
    """Check that creating a single task creates the expected task files with expected content in the expected location"""
    runner = CliRunner()

    runner.invoke(
        task,
        [
            "create",
            str(PurePath(course_path, exercise_id)),
            task_id,
            "-d",
            tmp_dir_path,
        ],
    )

    for expected_file in expected_files:
        task_file_path = Path(
            tmp_dir_path, exercise_id, task_id, expected_file.filename
        )

        try:
            file = open(task_file_path)
        except FileNotFoundError:
            pytest.fail(
                f'Expected file "{expected_file.filename}" not found in temporary directory.'
            )
        else:
            if expected_file.content is not None:
                with file:
                    content = file.read()
                    assert content == expected_file.content


def test_create_task_single_creates_timdata_file(tmp_dir):
    exercise_id = "exercise-a"
    task_id = "t2"
    timdata_file_name = ".timdata"
    timdata_file_path = Path(tmp_dir_path, exercise_id, task_id, timdata_file_name)
    runner = CliRunner()

    runner.invoke(
        task,
        [
            "create",
            f"users/test-user-1/course-2/{exercise_id}",
            task_id,
            "-d",
            tmp_dir_path,
        ],
    )

    assert timdata_file_path.is_file()


def test_create_task_with_force_flag(tmp_dir):
    pass


def test_create_all_tasks_for_exercise(tmp_dir):
    # TODO: test that creating tasks with --all flag works
    pass


# TASK SUBMIT


def test_task_submit():
    """Submit an answer to a course."""
    pass


def test_task_submit_invalid_path():
    """Submit an answer to a course."""
    pass


def test_task_submit_invalid_answer_file():
    """Submit an answer to a course."""
    pass


def test_task_submit_invalid_meta_data():
    """Submit an answer to a course."""
    pass


# TASK RESET


def test_task_reset(tmp_dir):
    pass
